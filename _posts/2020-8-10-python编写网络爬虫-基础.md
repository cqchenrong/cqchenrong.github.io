---
post_url: ''
excerpt_separator: <!--more-->
title: pyhton编写网络爬虫
date: 2020-8-10 10:00:00
categories: ["python","爬虫","request","XPath","beautifulsoup4"]
tags: ["爬虫"]
# published: false   #站点不显示此文章
---

## 认识网络爬虫

网络爬虫又被称为网页蜘蛛，网络机器人，是一种用来抓取万维网信息的程序或者脚本

有了网络爬虫技术我们可以更加轻松的得到网络上的信息，在现实生活中，网络爬虫的意义无处不在，比如用搜索引擎搜索数据、数据分析要用到的数据、人工智能所需的海量数据、抢票软件的自动请求抢票等。

<!--more-->

网络爬虫的程序一般在linux系统上跑，原因很多。

如何在linux系统上跑（待续写）

## 实现网络爬虫

### 向网页请求数据——requests库

方便的向网页请求数据，使用requests库，它是一个 python的http客户端，使用起来方便安全：

方便在于，我们只需要写一个url就可以向网页请求数据，且发送表单数据无需手动转码，而且接收的数据读取方便，它的官网有解释

安全在于，还不理解，官网有解释

安装：pip install requests

requests虽然好用，但也需要有一定的web请求的知识，才能更好的利用requests，比如开代理，网页的证书验证，防止跨站请求，保存浏览器会话数据的session等，requests在处理这些方面都有一定的方式，比如网页的证书验证，requests可以在请求url的时候，添加verify=False关闭证书验证，从而获取到网页数据。官网可看这些如何处理，如果不了解这些web请求的知识，可能到官网看到这些的处理，也不知道意义和作用

### 网页数据请求后，如何更快的从网页中提取想要的数据

有如下三种方式：

- 可以通过正则表达式匹配，但有点复杂


- 因此可以通过XPath，全称（XML Path Language）XML路径语言，它可以快速定位XML文本节点，也适用于HTML中的节点，使用XPath的关键点在于理清文本各节点之间的关系，通过关系层级得到节点数据，它是在网页上安装插件（谷歌浏览器）然后在浏览器使用，语法如何，可以百度

  按如果我们用requests得到网页数据后，如何通过解析呢？使用lxml库，它可以将网页文本数据，组装成html对象数据，对于html对象数据，我们就可以使用lxml解析了

  lxml是一种使用python编写的库，可以迅速、灵活的处理xml，支持XPath，可以通过XPath的语法解析

- Beautiful Soup 是一个python的库，主要功能是从网页中获取数据，通过解析文档为用户提供需要抓取的数据，提供一些简单的、python式的函数来处理导航、搜索、修改、分析树等功能，使用起来简单，目前使用 beautifulsoup4的版本，简称bs4，安装：pip install beautifulsoup4

  Beautiful Soup需要解析器来完成文本的解析，有如下解析器（markup是要解析的内容）

  | 解析器               | 使用方法                             | 优势                                                      | 劣势                                         |
  | -------------------- | ------------------------------------ | --------------------------------------------------------- | -------------------------------------------- |
  | python标准库的解析器 | BeautifulSoup(markup, "html.parser") | python的内置标准库、执行速度时钟，文档容错能力强          | python2.7.3及python3.2.2之前的版本容错能力差 |
  | lxml HTML解析器      | BeautifulSoup(markup, "lxml")        | 速度快、文档容错能力强                                    | 需要安装C语言库                              |
  | lxml XML解析器       | BeautifulSoup(markup, "xml")         | 速度快、唯一支持XML的解析器                               | 需要安装C语言库                              |
  | html5lib             | BeautifulSoup(markup, "html5lib")    | 最好的容错性、以浏览器的方式解析文档、生成html5格式的文档 | 速度慢，不依赖外部扩展                       |

  在Beautiful Soup中使用lxml 库解析：安装：pip install lxml，Beautiful Soup如何使用看官网

  ## 解析完数据后，将数据存放在数据库

  根据数据类型来选择使用那种数据库，关于数据库和python的交互（待写）